{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "mount_file_id": "1908C2gPZ-ZjU6e6OJ_3J4f0MM4RFfPjk",
      "authorship_tag": "ABX9TyOCOsUJTK6u+Dj7kBYxDdSq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shubhangi105/BenchmarkingFHEModels/blob/main/Encrypted_NN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training neural netwrok using QAT and measuring accuracy with FHE\n",
        "\n",
        "Benchmarking accuracy in neural networks on Concrete ML for FHE. The code is profiled and time performance is reported on the outputs of the cells and the project report."
      ],
      "metadata": {
        "id": "MLldka3hRpht"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Installation"
      ],
      "metadata": {
        "id": "ezL52HfUTF3T"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "7UAnUVdTXiVT",
        "outputId": "bc99214c-e500-41ca-b502-41c3d0275782"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (23.1.2)\n",
            "Collecting pip\n",
            "  Downloading pip-24.0-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (0.42.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (67.7.2)\n",
            "Collecting setuptools\n",
            "  Downloading setuptools-69.0.3-py3-none-any.whl (819 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m819.5/819.5 kB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: setuptools, pip\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 67.7.2\n",
            "    Uninstalling setuptools-67.7.2:\n",
            "      Successfully uninstalled setuptools-67.7.2\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 23.1.2\n",
            "    Uninstalling pip-23.1.2:\n",
            "      Successfully uninstalled pip-23.1.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.34.0 requires jedi>=0.16, which is not installed.\n",
            "lida 0.0.10 requires fastapi, which is not installed.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "lida 0.0.10 requires python-multipart, which is not installed.\n",
            "lida 0.0.10 requires uvicorn, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed pip-24.0 setuptools-69.0.3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "_distutils_hack",
                  "pkg_resources",
                  "setuptools"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting concrete-ml\n",
            "  Downloading concrete_ml-1.4.0-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting boto3<2.0.0,>=1.23.5 (from concrete-ml)\n",
            "  Downloading boto3-1.34.34-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting brevitas==0.8.0 (from concrete-ml)\n",
            "  Downloading brevitas-0.8.0-py3-none-any.whl (357 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m357.3/357.3 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting certifi==2023.07.22 (from concrete-ml)\n",
            "  Downloading certifi-2023.7.22-py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting concrete-python==2.5.0 (from concrete-ml)\n",
            "  Downloading concrete_python-2.5-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (8.4 kB)\n",
            "Collecting fastapi<0.103.0,>=0.102.0 (from concrete-ml)\n",
            "  Downloading fastapi-0.102.0-py3-none-any.whl.metadata (24 kB)\n",
            "Collecting gitpython==3.1.41 (from concrete-ml)\n",
            "  Downloading GitPython-3.1.41-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting hummingbird-ml==0.4.8 (from hummingbird-ml[onnx]==0.4.8->concrete-ml)\n",
            "  Downloading hummingbird_ml-0.4.8-py2.py3-none-any.whl (164 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m164.6/164.6 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy==1.23.5 in /usr/local/lib/python3.10/dist-packages (from concrete-ml) (1.23.5)\n",
            "Collecting onnx==1.13.1 (from concrete-ml)\n",
            "  Downloading onnx-1.13.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.5/13.5 MB\u001b[0m \u001b[31m52.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting onnxoptimizer==0.3.10 (from concrete-ml)\n",
            "  Downloading onnxoptimizer-0.3.10-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (671 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m671.6/671.6 kB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting onnxruntime==1.13.1 (from concrete-ml)\n",
            "  Downloading onnxruntime-1.13.1-cp310-cp310-manylinux_2_27_x86_64.whl (4.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m55.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: protobuf==3.20.3 in /usr/local/lib/python3.10/dist-packages (from concrete-ml) (3.20.3)\n",
            "Collecting pytest-json-report==1.5.0 (from concrete-ml)\n",
            "  Downloading pytest_json_report-1.5.0-py3-none-any.whl (13 kB)\n",
            "Collecting scikit-learn==1.1.3 (from concrete-ml)\n",
            "  Downloading scikit_learn-1.1.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.5/30.5 MB\u001b[0m \u001b[31m37.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scipy==1.10.1 (from concrete-ml)\n",
            "  Downloading scipy-1.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.4/34.4 MB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting setuptools==65.6.3 (from concrete-ml)\n",
            "  Downloading setuptools-65.6.3-py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m48.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting skops==0.5.0 (from concrete-ml)\n",
            "  Downloading skops-0.5.0-py3-none-any.whl (92 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.8/92.8 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting skorch==0.11.0 (from concrete-ml)\n",
            "  Downloading skorch-0.11.0-py3-none-any.whl (155 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.1/155.1 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch==1.13.1 (from concrete-ml)\n",
            "  Downloading torch-1.13.1-cp310-cp310-manylinux1_x86_64.whl (887.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m887.5/887.5 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm<5.0.0,>=4.64.1 in /usr/local/lib/python3.10/dist-packages (from concrete-ml) (4.66.1)\n",
            "Collecting transformers<5.0.0,>=4.36.0 (from concrete-ml)\n",
            "  Downloading transformers-4.37.2-py3-none-any.whl.metadata (129 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.4/129.4 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions==4.5.0 in /usr/local/lib/python3.10/dist-packages (from concrete-ml) (4.5.0)\n",
            "Collecting uvicorn<0.22.0,>=0.21.0 (from concrete-ml)\n",
            "  Downloading uvicorn-0.21.1-py3-none-any.whl (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.8/57.8 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting xgboost==1.6.2 (from concrete-ml)\n",
            "  Downloading xgboost-1.6.2-py3-none-manylinux2014_x86_64.whl (255.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m255.9/255.9 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from brevitas==0.8.0->concrete-ml) (23.2)\n",
            "Collecting dependencies==2.0.1 (from brevitas==0.8.0->concrete-ml)\n",
            "  Downloading dependencies-2.0.1-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: importlib-resources>=6.1 in /usr/local/lib/python3.10/dist-packages (from concrete-python==2.5.0->concrete-ml) (6.1.1)\n",
            "Requirement already satisfied: networkx>=2.6 in /usr/local/lib/python3.10/dist-packages (from concrete-python==2.5.0->concrete-ml) (3.2.1)\n",
            "Collecting z3-solver>=4.12 (from concrete-python==2.5.0->concrete-ml)\n",
            "  Downloading z3_solver-4.12.5.0-py2.py3-none-manylinux2014_x86_64.whl.metadata (732 bytes)\n",
            "Collecting gitdb<5,>=4.0.1 (from gitpython==3.1.41->concrete-ml)\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting dill (from hummingbird-ml==0.4.8->hummingbird-ml[onnx]==0.4.8->concrete-ml)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting onnxconverter-common>=1.6.0 (from hummingbird-ml==0.4.8->hummingbird-ml[onnx]==0.4.8->concrete-ml)\n",
            "  Downloading onnxconverter_common-1.14.0-py2.py3-none-any.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from hummingbird-ml==0.4.8->hummingbird-ml[onnx]==0.4.8->concrete-ml) (5.9.5)\n",
            "Collecting onnxmltools<=1.11.0,>=1.6.0 (from hummingbird-ml[onnx]==0.4.8->concrete-ml)\n",
            "  Downloading onnxmltools-1.11.0-py2.py3-none-any.whl (302 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.4/302.4 kB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting skl2onnx<=1.12.0,>=1.7.0 (from hummingbird-ml[onnx]==0.4.8->concrete-ml)\n",
            "  Downloading skl2onnx-1.12-py2.py3-none-any.whl (279 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m279.3/279.3 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting coloredlogs (from onnxruntime==1.13.1->concrete-ml)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime==1.13.1->concrete-ml) (23.5.26)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime==1.13.1->concrete-ml) (1.12)\n",
            "Requirement already satisfied: pytest>=3.8.0 in /usr/local/lib/python3.10/dist-packages (from pytest-json-report==1.5.0->concrete-ml) (7.4.4)\n",
            "Collecting pytest-metadata (from pytest-json-report==1.5.0->concrete-ml)\n",
            "  Downloading pytest_metadata-3.1.0-py3-none-any.whl.metadata (8.6 kB)\n",
            "Requirement already satisfied: joblib>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.1.3->concrete-ml) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.1.3->concrete-ml) (3.2.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from skops==0.5.0->concrete-ml) (0.20.3)\n",
            "Requirement already satisfied: tabulate>=0.8.8 in /usr/local/lib/python3.10/dist-packages (from skops==0.5.0->concrete-ml) (0.9.0)\n",
            "Collecting nvidia-cuda-runtime-cu11==11.7.99 (from torch==1.13.1->concrete-ml)\n",
            "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m43.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu11==8.5.0.96 (from torch==1.13.1->concrete-ml)\n",
            "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu11==11.10.3.66 (from torch==1.13.1->concrete-ml)\n",
            "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch==1.13.1->concrete-ml)\n",
            "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==1.13.1->concrete-ml) (0.42.0)\n",
            "Collecting botocore<1.35.0,>=1.34.34 (from boto3<2.0.0,>=1.23.5->concrete-ml)\n",
            "  Downloading botocore-1.34.34-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting jmespath<2.0.0,>=0.7.1 (from boto3<2.0.0,>=1.23.5->concrete-ml)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Collecting s3transfer<0.11.0,>=0.10.0 (from boto3<2.0.0,>=1.23.5->concrete-ml)\n",
            "  Downloading s3transfer-0.10.0-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from fastapi<0.103.0,>=0.102.0->concrete-ml) (1.10.14)\n",
            "Collecting starlette<0.28.0,>=0.27.0 (from fastapi<0.103.0,>=0.102.0->concrete-ml)\n",
            "  Downloading starlette-0.27.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.36.0->concrete-ml) (3.13.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.36.0->concrete-ml) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.36.0->concrete-ml) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.36.0->concrete-ml) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.36.0->concrete-ml) (0.15.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.36.0->concrete-ml) (0.4.2)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn<0.22.0,>=0.21.0->concrete-ml) (8.1.7)\n",
            "Collecting h11>=0.8 (from uvicorn<0.22.0,>=0.21.0->concrete-ml)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.10/dist-packages (from botocore<1.35.0,>=1.34.34->boto3<2.0.0,>=1.23.5->concrete-ml) (2.8.2)\n",
            "Requirement already satisfied: urllib3<2.1,>=1.25.4 in /usr/local/lib/python3.10/dist-packages (from botocore<1.35.0,>=1.34.34->boto3<2.0.0,>=1.23.5->concrete-ml) (2.0.7)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython==3.1.41->concrete-ml)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.10.1->skops==0.5.0->concrete-ml) (2023.6.0)\n",
            "INFO: pip is looking at multiple versions of onnxconverter-common to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting onnxconverter-common>=1.6.0 (from hummingbird-ml==0.4.8->hummingbird-ml[onnx]==0.4.8->concrete-ml)\n",
            "  Downloading onnxconverter_common-1.13.0-py2.py3-none-any.whl (83 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.8/83.8 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: iniconfig in /usr/local/lib/python3.10/dist-packages (from pytest>=3.8.0->pytest-json-report==1.5.0->concrete-ml) (2.0.0)\n",
            "Requirement already satisfied: pluggy<2.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from pytest>=3.8.0->pytest-json-report==1.5.0->concrete-ml) (1.4.0)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /usr/local/lib/python3.10/dist-packages (from pytest>=3.8.0->pytest-json-report==1.5.0->concrete-ml) (1.2.0)\n",
            "Requirement already satisfied: tomli>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from pytest>=3.8.0->pytest-json-report==1.5.0->concrete-ml) (2.0.1)\n",
            "Requirement already satisfied: anyio<5,>=3.4.0 in /usr/local/lib/python3.10/dist-packages (from starlette<0.28.0,>=0.27.0->fastapi<0.103.0,>=0.102.0->concrete-ml) (3.7.1)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime==1.13.1->concrete-ml)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers<5.0.0,>=4.36.0->concrete-ml) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers<5.0.0,>=4.36.0->concrete-ml) (3.6)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime==1.13.1->concrete-ml) (1.3.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette<0.28.0,>=0.27.0->fastapi<0.103.0,>=0.102.0->concrete-ml) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.35.0,>=1.34.34->boto3<2.0.0,>=1.23.5->concrete-ml) (1.16.0)\n",
            "Downloading concrete_ml-1.4.0-py3-none-any.whl (220 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m220.3/220.3 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading certifi-2023.7.22-py3-none-any.whl (158 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.3/158.3 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading concrete_python-2.5-cp310-cp310-manylinux_2_28_x86_64.whl (65.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading GitPython-3.1.41-py3-none-any.whl (196 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.4/196.4 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading boto3-1.34.34-py3-none-any.whl (139 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.3/139.3 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fastapi-0.102.0-py3-none-any.whl (66 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.0/66.0 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading transformers-4.37.2-py3-none-any.whl (8.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m87.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading botocore-1.34.34-py3-none-any.whl (11.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.9/11.9 MB\u001b[0m \u001b[31m84.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading s3transfer-0.10.0-py3-none-any.whl (82 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.1/82.1 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading starlette-0.27.0-py3-none-any.whl (66 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading z3_solver-4.12.5.0-py2.py3-none-manylinux2014_x86_64.whl (56.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.9/56.9 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytest_metadata-3.1.0-py3-none-any.whl (10 kB)\n",
            "Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: z3-solver, smmap, setuptools, scipy, onnx, nvidia-cuda-nvrtc-cu11, jmespath, humanfriendly, h11, dill, dependencies, certifi, xgboost, uvicorn, starlette, scikit-learn, pytest-metadata, onnxoptimizer, onnxconverter-common, nvidia-cuda-runtime-cu11, nvidia-cublas-cu11, gitdb, coloredlogs, botocore, skorch, skl2onnx, s3transfer, pytest-json-report, onnxruntime, nvidia-cudnn-cu11, gitpython, fastapi, torch, skops, onnxmltools, boto3, transformers, hummingbird-ml, concrete-python, brevitas, concrete-ml\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 69.0.3\n",
            "    Uninstalling setuptools-69.0.3:\n",
            "      Successfully uninstalled setuptools-69.0.3\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.11.4\n",
            "    Uninstalling scipy-1.11.4:\n",
            "      Successfully uninstalled scipy-1.11.4\n",
            "  Attempting uninstall: certifi\n",
            "    Found existing installation: certifi 2023.11.17\n",
            "    Uninstalling certifi-2023.11.17:\n",
            "      Successfully uninstalled certifi-2023.11.17\n",
            "  Attempting uninstall: xgboost\n",
            "    Found existing installation: xgboost 2.0.3\n",
            "    Uninstalling xgboost-2.0.3:\n",
            "      Successfully uninstalled xgboost-2.0.3\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.2.2\n",
            "    Uninstalling scikit-learn-1.2.2:\n",
            "      Successfully uninstalled scikit-learn-1.2.2\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.1.0+cu121\n",
            "    Uninstalling torch-2.1.0+cu121:\n",
            "      Successfully uninstalled torch-2.1.0+cu121\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.35.2\n",
            "    Uninstalling transformers-4.35.2:\n",
            "      Successfully uninstalled transformers-4.35.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.34.0 requires jedi>=0.16, which is not installed.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "lida 0.0.10 requires python-multipart, which is not installed.\n",
            "bigframes 0.20.0 requires scikit-learn>=1.2.2, but you have scikit-learn 1.1.3 which is incompatible.\n",
            "torchaudio 2.1.0+cu121 requires torch==2.1.0, but you have torch 1.13.1 which is incompatible.\n",
            "torchdata 0.7.0 requires torch==2.1.0, but you have torch 1.13.1 which is incompatible.\n",
            "torchtext 0.16.0 requires torch==2.1.0, but you have torch 1.13.1 which is incompatible.\n",
            "torchvision 0.16.0+cu121 requires torch==2.1.0, but you have torch 1.13.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed boto3-1.34.34 botocore-1.34.34 brevitas-0.8.0 certifi-2023.7.22 coloredlogs-15.0.1 concrete-ml-1.4.0 concrete-python-2.5 dependencies-2.0.1 dill-0.3.8 fastapi-0.102.0 gitdb-4.0.11 gitpython-3.1.41 h11-0.14.0 humanfriendly-10.0 hummingbird-ml-0.4.8 jmespath-1.0.1 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 onnx-1.13.1 onnxconverter-common-1.13.0 onnxmltools-1.11.0 onnxoptimizer-0.3.10 onnxruntime-1.13.1 pytest-json-report-1.5.0 pytest-metadata-3.1.0 s3transfer-0.10.0 scikit-learn-1.1.3 scipy-1.10.1 setuptools-65.6.3 skl2onnx-1.12 skops-0.5.0 skorch-0.11.0 smmap-5.0.1 starlette-0.27.0 torch-1.13.1 transformers-4.37.2 uvicorn-0.21.1 xgboost-1.6.2 z3-solver-4.12.5.0\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "_distutils_hack",
                  "certifi",
                  "pkg_resources",
                  "setuptools"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: brevitas in /usr/local/lib/python3.10/dist-packages (0.8.0)\n",
            "Requirement already satisfied: torch>=1.5.1 in /usr/local/lib/python3.10/dist-packages (from brevitas) (1.13.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from brevitas) (23.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from brevitas) (65.6.3)\n",
            "Requirement already satisfied: dependencies==2.0.1 in /usr/local/lib/python3.10/dist-packages (from brevitas) (2.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.10/dist-packages (from brevitas) (4.5.0)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.1->brevitas) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.1->brevitas) (8.5.0.96)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.1->brevitas) (11.10.3.66)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.1->brevitas) (11.7.99)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.5.1->brevitas) (0.42.0)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.16.0+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.23.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.31.0)\n",
            "Collecting torch==2.1.0 (from torchvision)\n",
            "  Downloading torch-2.1.0-cp310-cp310-manylinux1_x86_64.whl.metadata (25 kB)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchvision) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchvision) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchvision) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchvision) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchvision) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchvision) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.1.0->torchvision)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m68.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.1.0->torchvision)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m41.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.1.0->torchvision)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m79.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch==2.1.0->torchvision)\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.1.0->torchvision)\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.1.0->torchvision)\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch==2.1.0->torchvision)\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.1.0->torchvision)\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.1.0->torchvision)\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu12==2.18.1 (from torch==2.1.0->torchvision)\n",
            "  Downloading nvidia_nccl_cu12-2.18.1-py3-none-manylinux1_x86_64.whl (209.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.8/209.8 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch==2.1.0->torchvision)\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchvision) (2.1.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch==2.1.0->torchvision)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.3.101-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2023.7.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.1.0->torchvision) (2.1.4)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.1.0->torchvision) (1.3.0)\n",
            "Downloading torch-2.1.0-cp310-cp310-manylinux1_x86_64.whl (670.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m670.2/670.2 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.3.101-py3-none-manylinux1_x86_64.whl (20.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.5/20.5 MB\u001b[0m \u001b[31m71.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.13.1\n",
            "    Uninstalling torch-1.13.1:\n",
            "      Successfully uninstalled torch-1.13.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "concrete-ml 1.4.0 requires torch==1.13.1, but you have torch 2.1.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.18.1 nvidia-nvjitlink-cu12-12.3.101 nvidia-nvtx-cu12-12.1.105 torch-2.1.0\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.1)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -U pip wheel setuptools\n",
        "#!pip install -r requirements.txt\n",
        "!pip install concrete-ml\n",
        "!pip install brevitas\n",
        "!pip install torchvision\n",
        "!pip install tqdm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "# Concrete-Python\n",
        "from concrete.fhe.compilation import Configuration\n",
        "\n",
        "# The QAT model\n",
        "from model import MNISTQATModel  # pylint: disable=no-name-in-module\n",
        "from torch import nn, optim\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "from torchvision import datasets, transforms\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Concrete ML\n",
        "from concrete.ml.torch.compile import compile_brevitas_qat_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ojo7UJOdYrfy",
        "outputId": "bd2b1c12-3cec-4c04-9bbd-9ac2ed01d91b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No CUDA runtime is found, using CUDA_HOME='/usr/local/cuda'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Neural Network set-up"
      ],
      "metadata": {
        "id": "8VtorfIiTX_v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Functions"
      ],
      "metadata": {
        "id": "I0SgNyeUUzvg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following functions are for training and testing of the model"
      ],
      "metadata": {
        "id": "ZgqK7iLdTpZe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, device, train_loader, optimizer, epoch, criterion):\n",
        "    \"\"\"Train the model.\"\"\"\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data).squeeze()\n",
        "        loss = criterion(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if epoch % 4 == 0 and batch_idx % 500 == 0:\n",
        "            print(\n",
        "                f\"Train Epoch: {epoch + 1} [{batch_idx}/{len(train_loader.dataset) // len(data)}\"\n",
        "                f\" ({100.0 * batch_idx / len(train_loader):.0f}%)]{'':5}\"\n",
        "                f\"\\tLoss: {loss.item():.6f}\"\n",
        "            )"
      ],
      "metadata": {
        "id": "1CAYntD1Y3jm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test(model, device, test_loader, epoch, criterion):\n",
        "    \"\"\"Test the model.\"\"\"\n",
        "\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data, target in tqdm(test_loader, disable=epoch % 4 != 0):\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data).squeeze()\n",
        "            test_loss += criterion(output, target).item()  # sum up batch loss\n",
        "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "\n",
        "    if epoch % 4 == 0:\n",
        "        print(\n",
        "            f\"Test set: Average loss: {test_loss:.4f}, \"\n",
        "            \"Accuracy: \"\n",
        "            f\"{correct}/{len(test_loader.dataset)} \"\n",
        "            f\"({100.0 * correct / len(test_loader.dataset):.0f}%)\"\n",
        "        )\n",
        "\n",
        "    return test_loss"
      ],
      "metadata": {
        "id": "6Evn3rn9Y-zp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def manage_dataset(train_kwargs, test_kwargs):\n",
        "    \"\"\"Get training and test parts of MNIST data-set.\"\"\"\n",
        "\n",
        "    transform = transforms.Compose(\n",
        "        [\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize((0.1307,), (0.3081,)),\n",
        "            transforms.Lambda(torch.flatten),\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    # Manage data-sets\n",
        "    dataset1 = datasets.MNIST(\"./data\", train=True, download=True, transform=transform)\n",
        "    dataset2 = datasets.MNIST(\"./data\", train=False, transform=transform)\n",
        "    train_loader = torch.utils.data.DataLoader(dataset1, **train_kwargs)\n",
        "    test_loader = torch.utils.data.DataLoader(dataset2, **test_kwargs)\n",
        "\n",
        "    return train_loader, test_loader"
      ],
      "metadata": {
        "id": "M4hM76r_ZFtW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following function is used to test the model, it can be done either using FHE execution or with FHE simulation  (i.e., on clear data).\n",
        "\n",
        "Evaluating models using FHE simulation is a very good habit to have when working with Concrete ML since it allows to check several aspects without having to wait for long FHE computations:\n",
        "- the impact of the FHE execution on the accuracy\n",
        "- the bit-widths of intermediate values, which impact FHE execution time"
      ],
      "metadata": {
        "id": "sf8oUSUwe-fl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "def compile_and_test(\n",
        "    model,\n",
        "    use_simulation,\n",
        "    test_data,\n",
        "    test_data_length,\n",
        "    test_target,\n",
        "    show_mlir,\n",
        "    current_index,\n",
        "):\n",
        "    # Compile the QAT model and test\n",
        "    configuration = Configuration(\n",
        "        enable_unsafe_features=True,  # This is for our tests only, never use that in prod\n",
        "        use_insecure_key_cache=True,  # This is for our tests only, never use that in prod\n",
        "        insecure_key_cache_location=\"/tmp/keycache\",\n",
        "    )\n",
        "\n",
        "    if use_simulation:\n",
        "        print(f\"\\n{current_index}. Compiling with the FHE simulation\")\n",
        "    else:\n",
        "        print(f\"\\n{current_index}. Compiling in FHE\")\n",
        "\n",
        "    q_module = compile_brevitas_qat_model(\n",
        "        model,\n",
        "        test_data,\n",
        "        configuration=configuration,\n",
        "        show_mlir=show_mlir,\n",
        "    )\n",
        "\n",
        "    # Check max bit-width\n",
        "    max_bit_width = q_module.fhe_circuit.graph.maximum_integer_bit_width()\n",
        "    #print(max_bit_width)\n",
        "\n",
        "    if max_bit_width > 8:\n",
        "        raise Exception(\n",
        "            f\"Too large bit-width ({max_bit_width}): training this network resulted in an \"\n",
        "            \"accumulator size that is too large. Possible solutions are:\"\n",
        "            \"    - this network should, on average, have 8bit accumulators. In your case an unlucky\"\n",
        "            f\"initialization resulted in {max_bit_width} accumulators. You can try to train the \"\n",
        "            \"network again\"\n",
        "            \"    - reduce the sparsity to reduce the number of active neuron connections\"\n",
        "            \"    - if the weight and activation bit-width is more than 2, you can try to reduce one\"\n",
        "            \"or both to a lower value\"\n",
        "        )\n",
        "\n",
        "    # Check the accuracy\n",
        "    if use_simulation:\n",
        "        print(\n",
        "            f\"\\n{current_index + 1}. Checking accuracy with the FHE simulation mode \"\n",
        "            f\"(length {test_data_length})\"\n",
        "        )\n",
        "    else:\n",
        "        print(f\"\\n{current_index + 1}. Checking accuracy in FHE (length {test_data_length})\")\n",
        "\n",
        "    # Key generation\n",
        "    if not use_simulation:\n",
        "        q_module.fhe_circuit.keygen()\n",
        "\n",
        "    correct_fhe = 0\n",
        "\n",
        "    # Reduce the test data, since very slow in FHE\n",
        "    reduced_test_data = test_data[0:test_data_length, :]\n",
        "    test_target = test_target[0:test_data_length, :]\n",
        "\n",
        "    fhe_mode = \"simulate\" if use_simulation else \"execute\"\n",
        "    t1 = time.perf_counter()\n",
        "    prediction = q_module.forward(reduced_test_data, fhe=fhe_mode)\n",
        "    t2 = time.perf_counter()\n",
        "    print(\"Time taken: \",t2-t1)\n",
        "\n",
        "    correct_fhe = (np.argmax(prediction, axis=1) == test_target.ravel()).sum()\n",
        "\n",
        "    # Final accuracy\n",
        "    return correct_fhe, reduced_test_data.shape[0], max_bit_width"
      ],
      "metadata": {
        "id": "-Med4F82ebrM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Settings\n",
        "\n",
        "Setting the different parameters of the model and loading the dataset."
      ],
      "metadata": {
        "id": "smta4V-se52e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Options: the most important ones\n",
        "epochs = 20\n",
        "sparsity = 4\n",
        "quantization_bits = 2\n",
        "do_training = True\n",
        "save_model = False\n",
        "\n",
        "# Options: can be changed\n",
        "lr = 0.02\n",
        "gamma = 0.33\n",
        "test_data_length_reduced = 2  # This is notably the length of the computation in FHE\n",
        "test_data_length_full = 10000\n",
        "\n",
        "# Options: no real reason to change\n",
        "show_mlir = False\n",
        "batch_size = 32\n",
        "test_batch_size = 32\n",
        "use_cuda_if_available = True\n",
        "seed = None\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "YX8iQhFNezF8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Seeding if we want to, to try to make everything as reproducible as possible."
      ],
      "metadata": {
        "id": "wi6LNJorfM01"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Seeding\n",
        "if seed is None:\n",
        "    seed = np.random.randint(0, 2**32 - 1)\n",
        "\n",
        "print(f\"\\nUsing seed {seed}\\n\")\n",
        "torch.manual_seed(seed);"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XWcmgVgVfN1v",
        "outputId": "d50cc381-06f8-41bd-8305-cb0dff05a440"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Using seed 2926655560\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seed = 2926655560\n",
        "print(f\"\\nUsing seed {seed}\\n\")\n",
        "torch.manual_seed(seed);"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E6xGFUIo7dUE",
        "outputId": "54d571fa-960f-4a3a-ce09-0300ec92197f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Using seed 2926655560\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Settings few things for the training."
      ],
      "metadata": {
        "id": "BuSBXbpofXvx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training and test arguments\n",
        "train_kwargs = {\"batch_size\": batch_size}\n",
        "test_kwargs = {\"batch_size\": test_batch_size}\n",
        "\n",
        "# Cuda management\n",
        "use_cuda = torch.cuda.is_available() and use_cuda_if_available\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "\n",
        "if use_cuda:\n",
        "    cuda_kwargs = {\"num_workers\": 1, \"pin_memory\": True, \"shuffle\": True}\n",
        "    train_kwargs.update(cuda_kwargs)\n",
        "    test_kwargs.update(cuda_kwargs)\n",
        "\n",
        "print(f\"\\nUsing {device} device\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c9ZO_BZ1fVwR",
        "outputId": "ddfffa3e-d655-4464-ffd5-ea4203986bc0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Using cpu device\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Managing the MNIST data set, and splitting it into a\n",
        "train and testing set."
      ],
      "metadata": {
        "id": "SNK4QkAHfk1o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Manage data-set\n",
        "train_loader, test_loader = manage_dataset(train_kwargs, test_kwargs)\n",
        "img_size = train_loader.dataset.data[0].shape[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h1gvoz25fbh8",
        "outputId": "b0acdc6c-03ee-4af1-d6f8-2fa25dc61f2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 248371862.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 19203502.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 69748990.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 13925825.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## QAT model training\n",
        "\n",
        "The model is defined in `model.py`."
      ],
      "metadata": {
        "id": "mC6OoReBfseY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Model definition\n",
        "model = MNISTQATModel(quantization_bits, quantization_bits)\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "SWQNQ4ITfnQy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below, depending on the value of do_training, you can either run the quantization-aware training, which might be time-consuming, or load a pretrained model by setting `do_training = False`."
      ],
      "metadata": {
        "id": "NeM2FC8Mf4Dm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training part\n",
        "print(\n",
        "    f\"Performing MNIST task with {quantization_bits}-bits in quantization and a \"\n",
        "    f\"sparsity of {sparsity}.\"\n",
        ")\n",
        "\n",
        "if do_training:\n",
        "\n",
        "    model.prune(sparsity, True)\n",
        "\n",
        "    print(\"\\n1. Training\")\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=0.0001)\n",
        "    scheduler = StepLR(optimizer, step_size=1, gamma=gamma)\n",
        "    loss_values = []\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        train(model, device, train_loader, optimizer, epoch, criterion)\n",
        "        cur_loss = test(model, device, test_loader, epoch, criterion)\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "        loss_values.append(cur_loss)\n",
        "\n",
        "    model.prune(sparsity, False)\n",
        "\n",
        "    # Plot the loss\n",
        "    fig = plt.figure()\n",
        "    plt.plot(loss_values)\n",
        "    fig.suptitle(\"Loss during QAT\")\n",
        "    plt.xlabel(\"Epochs\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.xticks(range(len(loss_values)))\n",
        "\n",
        "    if save_model:\n",
        "        # Export to ONNX\n",
        "        print(\"\\n2. Exporting to ONNX and saving the Brevitas model\")\n",
        "        inp = torch.rand((1, img_size * img_size)).to(device)\n",
        "        torch.onnx.export(model, inp, \"mnist.qat.onnx\", opset_version=14)\n",
        "        torch.save(model.state_dict(), \"state_dict.pt\")\n",
        "else:\n",
        "    print(\"\\n1. Loading pre-trained model\")\n",
        "    # Ensure that \"state_dict.pt\" is pulled through GIT LFS\n",
        "    checkpoint = torch.load(\"state_dict.pt\", map_location=device)\n",
        "    model.load_state_dict(checkpoint)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "hyNXn2d-f1Lw",
        "outputId": "1f5af0ec-2d01-4051-ada8-df28a71f4ed1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Performing MNIST task with 2-bits in quantization and a sparsity of 4.\n",
            "\n",
            "1. Training\n",
            "Train Epoch: 1 [0/1875 (0%)]     \tLoss: 8.985333\n",
            "Train Epoch: 1 [500/1875 (27%)]     \tLoss: 1.019910\n",
            "Train Epoch: 1 [1000/1875 (53%)]     \tLoss: 0.630351\n",
            "Train Epoch: 1 [1500/1875 (80%)]     \tLoss: 0.353047\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 313/313 [00:14<00:00, 21.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test set: Average loss: 0.0206, Accuracy: 8051/10000 (81%)\n",
            "Train Epoch: 5 [0/1875 (0%)]     \tLoss: 0.149230\n",
            "Train Epoch: 5 [500/1875 (27%)]     \tLoss: 0.573497\n",
            "Train Epoch: 5 [1000/1875 (53%)]     \tLoss: 0.455737\n",
            "Train Epoch: 5 [1500/1875 (80%)]     \tLoss: 0.200558\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 313/313 [00:07<00:00, 43.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test set: Average loss: 0.0120, Accuracy: 8875/10000 (89%)\n",
            "Train Epoch: 9 [0/1875 (0%)]     \tLoss: 0.204037\n",
            "Train Epoch: 9 [500/1875 (27%)]     \tLoss: 0.529180\n",
            "Train Epoch: 9 [1000/1875 (53%)]     \tLoss: 0.338629\n",
            "Train Epoch: 9 [1500/1875 (80%)]     \tLoss: 0.123368\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 313/313 [00:07<00:00, 43.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test set: Average loss: 0.0097, Accuracy: 9069/10000 (91%)\n",
            "Train Epoch: 13 [0/1875 (0%)]     \tLoss: 0.232755\n",
            "Train Epoch: 13 [500/1875 (27%)]     \tLoss: 0.721928\n",
            "Train Epoch: 13 [1000/1875 (53%)]     \tLoss: 0.586523\n",
            "Train Epoch: 13 [1500/1875 (80%)]     \tLoss: 0.152091\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 313/313 [00:07<00:00, 43.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test set: Average loss: 0.0099, Accuracy: 9058/10000 (91%)\n",
            "Train Epoch: 17 [0/1875 (0%)]     \tLoss: 0.135512\n",
            "Train Epoch: 17 [500/1875 (27%)]     \tLoss: 0.592692\n",
            "Train Epoch: 17 [1000/1875 (53%)]     \tLoss: 0.535859\n",
            "Train Epoch: 17 [1500/1875 (80%)]     \tLoss: 0.188149\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 313/313 [00:10<00:00, 30.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test set: Average loss: 0.0099, Accuracy: 9058/10000 (91%)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We prepare the ground truth, for final check of the model."
      ],
      "metadata": {
        "id": "IKQtU5aZnRmp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare tests\n",
        "test_data = np.zeros((len(test_loader.dataset), img_size * img_size))\n",
        "test_target = np.zeros((len(test_loader.dataset), 1))\n",
        "idx = 0\n",
        "\n",
        "for data, target in tqdm(test_loader):\n",
        "    target_np = target.cpu().numpy()\n",
        "    for idx_batch, im in enumerate(data.numpy()):\n",
        "        test_data[idx] = im\n",
        "        test_target[idx] = target_np[idx_batch]\n",
        "        idx += 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rtReS5yZf_Bi",
        "outputId": "9973f9bd-0e24-4bc8-b923-445339bcac18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 313/313 [00:03<00:00, 84.07it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Measuring accuracy"
      ],
      "metadata": {
        "id": "kAkTtGbGUnPq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Measuring accuracy with FHE simulation and FHE execution\n",
        "\n",
        "Finally, we measure:\n",
        "- accuracy with FHE simulation for the full test set\n",
        "- accuracy with FHE simulation for the reduced test set\n",
        "- accuracy in FHE for the reduced test set   \n",
        "\n",
        "and we check that accuracy with FHE simulation and in FHE are equivalent on the reduced test set.\n",
        "\n",
        "Running FHE computations on a too large reduced test set may be prohibitive since we're 100% on CPU."
      ],
      "metadata": {
        "id": "xfBF5QlznYur"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Test in the FHE simulation and in real FHE computation\n",
        "accuracy = {}\n",
        "current_index = 3\n",
        "\n",
        "for use_simulation, use_full_dataset in [(True, True), (True, False), (False, False)]:\n",
        "    test_data_length = test_data_length_full if use_full_dataset else test_data_length_reduced\n",
        "\n",
        "    correct_fhe, test_data_shape_0, max_bit_width = compile_and_test(\n",
        "        model.cpu(),\n",
        "        use_simulation,\n",
        "        test_data,\n",
        "        test_data_length,\n",
        "        test_target,\n",
        "        show_mlir,\n",
        "        current_index,\n",
        "    )\n",
        "\n",
        "    current_index += 2\n",
        "    current_accuracy = correct_fhe / test_data_shape_0\n",
        "\n",
        "    print(\n",
        "        f\"Accuracy in {'Simulation' if use_simulation else 'FHE'} with length {test_data_length}: \"\n",
        "        f\"{correct_fhe}/{test_data_shape_0} = \"\n",
        "        f\"{current_accuracy:.4f}, in {max_bit_width}-bits\"\n",
        "    )\n",
        "\n",
        "    if (use_simulation, use_full_dataset) == (True, True):\n",
        "        accuracy[\"FHE Simulation full\"] = current_accuracy\n",
        "    elif (use_simulation, use_full_dataset) == (True, False):\n",
        "        accuracy[\"FHE simulation short\"] = current_accuracy\n",
        "    else:\n",
        "        assert (use_simulation, use_full_dataset) == (False, False)\n",
        "        accuracy[\"FHE short\"] = current_accuracy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mkeELB7hmzsX",
        "outputId": "71e22024-7486-43e5-df04-6dfdbb68733b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "3. Compiling with the FHE simulation\n",
            "\n",
            "4. Checking accuracy with the FHE simulation mode (length 10000)\n",
            "Accuracy in Simulation with length 10000: 9058/10000 = 0.9058, in 6-bits\n",
            "\n",
            "5. Compiling with the FHE simulation\n",
            "\n",
            "6. Checking accuracy with the FHE simulation mode (length 2)\n",
            "Accuracy in Simulation with length 2: 2/2 = 1.0000, in 6-bits\n",
            "\n",
            "7. Compiling in FHE\n",
            "\n",
            "8. Checking accuracy in FHE (length 2)\n",
            "Accuracy in FHE with length 2: 2/2 = 1.0000, in 6-bits\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Checking accuracy and time for FHE simulation and FHE execution for reduced datapoints"
      ],
      "metadata": {
        "id": "p7IyOPdSPIzs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Test in the FHE simulation and in real FHE computation\n",
        "accuracy = {}\n",
        "current_index = 3\n",
        "\n",
        "for use_simulation, use_full_dataset in [(True, False), (False, False)]:\n",
        "    test_data_length = test_data_length_full if use_full_dataset else test_data_length_reduced\n",
        "\n",
        "    correct_fhe, test_data_shape_0, max_bit_width = compile_and_test(\n",
        "        model.cpu(),\n",
        "        use_simulation,\n",
        "        test_data,\n",
        "        test_data_length,\n",
        "        test_target,\n",
        "        show_mlir,\n",
        "        current_index,\n",
        "    )\n",
        "\n",
        "    current_index += 2\n",
        "    current_accuracy = correct_fhe / test_data_shape_0\n",
        "\n",
        "    print(\n",
        "        f\"Accuracy in {'Simulation' if use_simulation else 'FHE'} with length {test_data_length}: \"\n",
        "        f\"{correct_fhe}/{test_data_shape_0} = \"\n",
        "        f\"{current_accuracy:.4f}, in {max_bit_width}-bits\"\n",
        "    )\n",
        "\n",
        "    if (use_simulation, use_full_dataset) == (True, False):\n",
        "        accuracy[\"FHE simulation short\"] = current_accuracy\n",
        "    else:\n",
        "        assert (use_simulation, use_full_dataset) == (False, False)\n",
        "        accuracy[\"FHE short\"] = current_accuracy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lyn-ALgfa83y",
        "outputId": "d91f1604-dfe9-42c5-f23d-8d217126b929"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "3. Compiling with the FHE simulation\n",
            "\n",
            "4. Checking accuracy with the FHE simulation mode (length 2)\n",
            "Time taken:  0.018122289000075398\n",
            "Accuracy in Simulation with length 2: 2/2 = 1.0000, in 6-bits\n",
            "\n",
            "5. Compiling in FHE\n",
            "\n",
            "6. Checking accuracy in FHE (length 2)\n",
            "Time taken:  182.96037620200013\n",
            "Accuracy in FHE with length 2: 2/2 = 1.0000, in 6-bits\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Checking accuracy and time for FHE-disable (without FHE) for reduced dataset"
      ],
      "metadata": {
        "id": "0fAu9p4TPS8h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compile_and_test(\n",
        "    model,\n",
        "    use_simulation,\n",
        "    test_data,\n",
        "    test_data_length,\n",
        "    test_target,\n",
        "    show_mlir,\n",
        "    current_index,\n",
        "):\n",
        "    # Compile the QAT model and test\n",
        "    configuration = Configuration(\n",
        "        enable_unsafe_features=True,  # This is for our tests only, never use that in prod\n",
        "        use_insecure_key_cache=True,  # This is for our tests only, never use that in prod\n",
        "        insecure_key_cache_location=\"/tmp/keycache\",\n",
        "    )\n",
        "\n",
        "    if use_simulation:\n",
        "        print(f\"\\n{current_index}. Compiling with the FHE simulation\")\n",
        "    else:\n",
        "        print(f\"\\n{current_index}. Compiling in FHE\")\n",
        "\n",
        "    q_module = compile_brevitas_qat_model(\n",
        "        model,\n",
        "        test_data,\n",
        "        configuration=configuration,\n",
        "        show_mlir=show_mlir,\n",
        "    )\n",
        "\n",
        "    # Check max bit-width\n",
        "    max_bit_width = q_module.fhe_circuit.graph.maximum_integer_bit_width()\n",
        "    #print(max_bit_width)\n",
        "\n",
        "    if max_bit_width > 8:\n",
        "        raise Exception(\n",
        "            f\"Too large bit-width ({max_bit_width}): training this network resulted in an \"\n",
        "            \"accumulator size that is too large. Possible solutions are:\"\n",
        "            \"    - this network should, on average, have 8bit accumulators. In your case an unlucky\"\n",
        "            f\"initialization resulted in {max_bit_width} accumulators. You can try to train the \"\n",
        "            \"network again\"\n",
        "            \"    - reduce the sparsity to reduce the number of active neuron connections\"\n",
        "            \"    - if the weight and activation bit-width is more than 2, you can try to reduce one\"\n",
        "            \"or both to a lower value\"\n",
        "        )\n",
        "\n",
        "    # Check the accuracy\n",
        "    if use_simulation:\n",
        "        print(\n",
        "            f\"\\n{current_index + 1}. Checking accuracy with the FHE simulation mode \"\n",
        "            f\"(length {test_data_length})\"\n",
        "        )\n",
        "    else:\n",
        "        print(f\"\\n{current_index + 1}. Checking accuracy in FHE (length {test_data_length})\")\n",
        "\n",
        "    # Key generation\n",
        "    if not use_simulation:\n",
        "        q_module.fhe_circuit.keygen()\n",
        "\n",
        "    correct_fhe = 0\n",
        "\n",
        "    # Reduce the test data, since very slow in FHE\n",
        "    reduced_test_data = test_data[0:test_data_length, :]\n",
        "    test_target = test_target[0:test_data_length, :]\n",
        "\n",
        "    fhe_mode = \"disable\" if use_simulation else \"execute\"\n",
        "    t1 = time.perf_counter()\n",
        "    prediction = q_module.forward(reduced_test_data, fhe=fhe_mode)\n",
        "    t2 = time.perf_counter()\n",
        "    print(\"Time taken: \",t2-t1)\n",
        "\n",
        "    correct_fhe = (np.argmax(prediction, axis=1) == test_target.ravel()).sum()\n",
        "\n",
        "    # Final accuracy\n",
        "    return correct_fhe, reduced_test_data.shape[0], max_bit_width"
      ],
      "metadata": {
        "id": "rj9_SZ8kmXtO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test in the FHE simulation and in real FHE computation\n",
        "accuracy = {}\n",
        "current_index = 3\n",
        "\n",
        "for use_simulation, use_full_dataset in [(True, False)]:\n",
        "    test_data_length = test_data_length_full if use_full_dataset else test_data_length_reduced\n",
        "\n",
        "    correct_fhe, test_data_shape_0, max_bit_width = compile_and_test(\n",
        "        model.cpu(),\n",
        "        use_simulation,\n",
        "        test_data,\n",
        "        test_data_length,\n",
        "        test_target,\n",
        "        show_mlir,\n",
        "        current_index,\n",
        "    )\n",
        "\n",
        "    current_index += 2\n",
        "    current_accuracy = correct_fhe / test_data_shape_0\n",
        "\n",
        "    print(\n",
        "        f\"Accuracy in {'Simulation' if use_simulation else 'FHE'} with length {test_data_length}: \"\n",
        "        f\"{correct_fhe}/{test_data_shape_0} = \"\n",
        "        f\"{current_accuracy:.4f}, in {max_bit_width}-bits\"\n",
        "    )\n",
        "\n",
        "    if (use_simulation, use_full_dataset) == (True, False):\n",
        "        accuracy[\"FHE simulation short\"] = current_accuracy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gEPB_X8cmqoS",
        "outputId": "d71acea7-1d4e-4030-cd43-472d5b31b168"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "3. Compiling with the FHE simulation\n",
            "\n",
            "4. Checking accuracy with the FHE simulation mode (length 2)\n",
            "Time taken:  0.05006195199985086\n",
            "Accuracy in Simulation with length 2: 2/2 = 1.0000, in 6-bits\n"
          ]
        }
      ]
    }
  ]
}